{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db003ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001002   Male      No          0      Graduate            No   \n",
      "1  LP001003   Male     Yes          1      Graduate            No   \n",
      "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
      "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
      "4  LP001008   Male      No          0      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0         NaN             360.0   \n",
      "1             4583             1508.0       128.0             360.0   \n",
      "2             3000                0.0        66.0             360.0   \n",
      "3             2583             2358.0       120.0             360.0   \n",
      "4             6000                0.0       141.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area Loan_Status  \n",
      "0             1.0         Urban           Y  \n",
      "1             1.0         Rural           N  \n",
      "2             1.0         Urban           Y  \n",
      "3             1.0         Urban           Y  \n",
      "4             1.0         Urban           Y  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the dataset\n",
    "dataset = pd.read_csv('Loan_Train.csv')\n",
    "\n",
    "# Check if the dataset loaded properly\n",
    "print(dataset.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e169830c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
      "0     1.0      0.0         0.0          1            0.0             5849   \n",
      "1     1.0      1.0         1.0          1            0.0             4583   \n",
      "2     1.0      1.0         0.0          1            1.0             3000   \n",
      "3     1.0      1.0         0.0          0            0.0             2583   \n",
      "4     1.0      0.0         0.0          1            0.0             6000   \n",
      "\n",
      "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
      "0                0.0         NaN             360.0             1.0   \n",
      "1             1508.0       128.0             360.0             1.0   \n",
      "2                0.0        66.0             360.0             1.0   \n",
      "3             2358.0       120.0             360.0             1.0   \n",
      "4                0.0       141.0             360.0             1.0   \n",
      "\n",
      "   Property_Area  Loan_Status  \n",
      "0            1.0            1  \n",
      "1            0.0            0  \n",
      "2            1.0            1  \n",
      "3            1.0            1  \n",
      "4            1.0            1  \n"
     ]
    }
   ],
   "source": [
    "# Drop the column \"Load_ID\"\n",
    "dataset.drop('Loan_ID', axis=1, inplace=True)\n",
    "\n",
    "# Converting specific categorical values to numeric values- I decided to convert text values as well.\n",
    "categorical_mapping = {\n",
    "    'Gender': {'Male': 1, 'Female': 2},\n",
    "    'Married': {'No': 0, 'Yes': 1},\n",
    "    'Dependents': {'0': 0, '1': 1, '2': 2, '3+': 3},\n",
    "    'Education': {'Not Graduate': 0, 'Graduate': 1},\n",
    "    'Property_Area': {'Rural': 0, 'Urban': 1},\n",
    "    'Self_Employed': {'No': 0, 'Yes': 1},\n",
    "    'Loan_Status': {'N': 0, 'Y': 1}\n",
    "}\n",
    "\n",
    "for col, mapping in categorical_mapping.items():\n",
    "    dataset[col] = dataset[col].map(mapping)\n",
    "\n",
    "# Display the modified dataset\n",
    "print(dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccbfa96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set - Features shape: (491, 11)\n",
      "Training set - Target shape: (491,)\n",
      "Test set - Features shape: (123, 11)\n",
      "Test set - Target shape: (123,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = dataset.drop('Loan_Status', axis=1)\n",
    "y = dataset['Loan_Status']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes\n",
    "print(\"Training set - Features shape:\", X_train.shape)\n",
    "print(\"Training set - Target shape:\", y_train.shape)\n",
    "print(\"Test set - Features shape:\", X_test.shape)\n",
    "print(\"Test set - Target shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dde3e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a37421d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7398373983739838\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = dataset.drop('Loan_Status', axis=1)\n",
    "y = dataset['Loan_Status']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with Min-Max scaler and KNN classifier\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the pipeline on the test data\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15f4158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('scaler', MinMaxScaler()),\n",
      "                ('classifier', LogisticRegression())])\n",
      "Best hyperparameters: {'classifier': LogisticRegression(), 'classifier__C': 1.0}\n",
      "Accuracy: 0.7886178861788617\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create a pipeline with SimpleImputer, MinMaxScaler, and KNN classifier\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define the search space - not sure if this method will work- may need to test in seperate code\n",
    "search_space = [\n",
    "    {'classifier': [KNeighborsClassifier()],\n",
    "     'classifier__n_neighbors': range(1, 11)},\n",
    "    {'classifier': [LogisticRegression()],\n",
    "     'classifier__C': [0.1, 1.0, 10.0]},\n",
    "    {'classifier': [RandomForestClassifier()],\n",
    "     'classifier__n_estimators': [100, 200, 300]}\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, search_space, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best model and hyperparameters\n",
    "print(\"Best model:\", grid_search.best_estimator_)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d3a0fd",
   "metadata": {},
   "source": [
    "After analyzing the grid search results, it's apparent that the top-performing model is a pipeline. This successful pipeline comprises a SimpleImputer, a MinMaxScaler and a Logistic Regression classifier working collaboratively. Additionally, this effective model has specific, pre-established hyperparameters which were included in its construction. These hyperparameters are as follows: 'classifier': LogisticRegression(), 'classifier__C': 1.0.\n",
    "\n",
    "Perhaps the most impressive aspect of this best-fit model is its accuracy while being tested|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a21bd",
   "metadata": {},
   "source": [
    "We tackled the task of building a classification model for our dataset by crafting an efficient pipeline. This naturally included useful steps to correct for scaling and to initialize a KNN classifier as default. Performing this operation culminated in success, and we applied evaluation metrics on the produced pipeline against our testing data resulting in a preliminary accuracy of 0.74.\n",
    "\n",
    "Going further, we deemed it necessary to improve upon this preliminary score through exhaustive search algorithms. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
